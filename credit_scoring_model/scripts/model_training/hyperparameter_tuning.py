"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç:
1. –ó–∞–≥—Ä—É–∑–∫—É –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å—ã—Ä—ã—Ö, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è –≤ Pipeline)
2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ—Ç–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
3. –ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é GridSearchCV
4. –û—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
"""

import sys
import warnings
from pathlib import Path
from typing import Any, Dict, List, Tuple

import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    f1_score,
    precision_score,
    recall_score,
    roc_auc_score,
)
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from tqdm import tqdm

warnings.filterwarnings("ignore")

# –§–∏–∫—Å–∏—Ä—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –Ω–∞ Windows
sys.stdout.reconfigure(encoding='utf-8')


def load_processed_data(
    data_dir: str = "data/processed",
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—ã—Ä—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ eda_features.csv (—Ñ–∏—á–∏) –∏ eda_target.csv (—Ç–∞—Ä–≥–µ—Ç),
    –∑–∞—Ç–µ–º –¥–µ–ª–∏—Ç –Ω–∞ train/test —Å –ø–æ–º–æ—â—å—é train_test_split (test_size=0.2, stratify –ø–æ y –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤).
    –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º EDA, –≥–¥–µ —Ñ–∏—á–∏ –∏ —Ç–∞—Ä–≥–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω—ã, –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö.

    Args:
        data_dir: –ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏

    Returns:
        Tuple: (X_train, X_test, y_train, y_test)
    """
    data_path = Path(data_dir)

    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Å—ã—Ä—ã—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ EDA...")

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ 
        X_full = pd.read_csv(data_path / "eda_features.csv")
        y_full = pd.read_csv(data_path / "eda_target.csv")['target'].squeeze()  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É 'target'

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test —Å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
        X_train, X_test, y_train, y_test = train_test_split(
            X_full, y_full, test_size=0.2, random_state=42, stratify=y_full
        )

        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏ —Ä–∞–∑–±–∏—Ç–æ:")
        print(f"  X_train: {X_train.shape}")
        print(f"  X_test: {X_test.shape}")
        print(f"  y_train: {y_train.shape}")
        print(f"  y_test: {y_test.shape}")

        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö
        print("\n–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö:")
        print("  - –ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω–µ –≤—Ö–æ–¥–∏—Ç –ª–∏ —Ç–∞—Ä–≥–µ—Ç –≤ —Ñ–∏—á–∏:")
        print(f"    –¶–µ–ª—å –≤ X_train? {'default.payment.next.month' in X_train.columns or 'y' in X_train.columns or 'target' in X_train.columns}")
        print("  - –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è y_train —Å X_train (|corr| > 0.95):")
        correlations = X_train.corrwith(y_train)
        high_corr = correlations[abs(correlations) > 0.95]
        if not high_corr.empty:
            print(f"    –í—ã—Å–æ–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –Ω–∞–π–¥–µ–Ω—ã:\n{high_corr}")
        else:
            print("    –ù–µ—Ç —Ñ–∏—á —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π (>0.95).")

        return X_train, X_test, y_train, y_test
    except FileNotFoundError as e:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ eda_features.csv –∏ eda_target.csv —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ data/processed/ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ EDA.")
        raise


def create_preprocessor(X_train: pd.DataFrame) -> ColumnTransformer:
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

    Args:
        X_train: –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

    Returns:
        ColumnTransformer: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    """
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞...")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    numeric_features = X_train.select_dtypes(
        include=["int64", "float64"]
    ).columns.tolist()
    categorical_features = X_train.select_dtypes(
        include=["object", "category"]
    ).columns.tolist()

    preprocessor = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numeric_features),
            ("cat", OneHotEncoder(drop="first", handle_unknown="ignore"), categorical_features),
        ]
    )

    print(
        f"–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–æ–∑–¥–∞–Ω –¥–ª—è {len(numeric_features)} —á–∏—Å–ª–æ–≤—ã—Ö –∏ {len(categorical_features)} –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
    )

    return preprocessor


def define_parameter_grids() -> List[Dict[str, Any]]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Å–µ—Ç–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞.
    –ö–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç —Å–≤–æ–π dict —Å –º–æ–¥–µ–ª—å—é –∏ –µ–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –º–æ–¥–µ–ª—å—é –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è GridSearchCV
    """
    print("\n–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö —Å–µ—Ç–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")

    param_grids = [
        # Logistic Regression
        {
            "model": LogisticRegression(max_iter=1000, random_state=42, class_weight="balanced"),
            "params": {
                "classifier__C": [0.01, 0.1, 1],  # –î–æ–±–∞–≤–ª–µ–Ω 0.01 –¥–ª—è —Å–∏–ª—å–Ω–µ–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
                "classifier__penalty": ["l2"],
                "classifier__solver": ["liblinear"],
            }
        },
        # Random Forest
        {
            "model": RandomForestClassifier(random_state=42, class_weight="balanced"),
            "params": {
                "classifier__n_estimators": [50, 100],
                "classifier__max_depth": [5, 10, 15],  # –î–æ–±–∞–≤–ª–µ–Ω–∞ –≥–ª—É–±–∏–Ω–∞ 5 –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –æ–≤–µ—Ä—Ñ–∏—Ç–∞
                "classifier__min_samples_split": [2, 5, 10],  # –î–æ–±–∞–≤–ª–µ–Ω 10 –¥–ª—è –ª–∏—Å—Ç–æ—á–∫–æ–≤
                "classifier__min_samples_leaf": [1, 2, 4],  # –î–æ–±–∞–≤–ª–µ–Ω–æ 4
            }
        },
    ]

    print(f"–°–æ–∑–¥–∞–Ω–æ {len(param_grids)} —Å–µ—Ç–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:")
    for i, grid in enumerate(param_grids):
        model_name = grid["model"].__class__.__name__
        print(f"  {i+1}. {model_name}")

    return param_grids


def perform_grid_search(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    preprocessor: ColumnTransformer,
    param_grids: List[Dict[str, Any]],
    cv: int = 5,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 5 –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π CV
    n_jobs: int = -1,
) -> Dict[str, Any]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ —Å–µ—Ç–∫–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.

    Args:
        X_train: –û–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        y_train: –û–±—É—á–∞—é—â–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        preprocessor: –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        param_grids: –°–ø–∏—Å–æ–∫ —Å–µ—Ç–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        cv: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
        n_jobs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤

    Returns:
        Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ —Å–µ—Ç–∫–µ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    """
    print(f"\n" + "=" * 60)
    print("–ü–û–ò–°–ö –ü–û –°–ï–¢–ö–ï –ü–ê–†–ê–ú–ï–¢–†–û–í")
    print("=" * 60)

    results = {}

    for item in tqdm(param_grids, desc="–ü–æ–∏—Å–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", unit="–º–æ–¥–µ–ª—å"):
        model = item["model"]
        param_grid = item["params"]
        model_name = model.__class__.__name__

        print(f"\n–ü–æ–∏—Å–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è {model_name}...")

        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å –º–æ–¥–µ–ª—å—é
            pipeline = Pipeline([
                ("preprocessor", preprocessor),
                ("classifier", model),
            ])

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–æ —Å–µ—Ç–∫–µ
            grid_search = GridSearchCV(
                pipeline, param_grid, cv=cv, scoring="roc_auc", n_jobs=n_jobs, verbose=0  # –£–º–µ–Ω—å—à–µ–Ω verbose –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã
            )

            # –û–±—É—á–∞–µ–º
            grid_search.fit(X_train, y_train)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results[model_name] = {
                "best_estimator": grid_search.best_estimator_,
                "best_params": grid_search.best_params_,
                "best_score": grid_search.best_score_,
                "cv_results": grid_search.cv_results_,
            }

            print(f"{model_name} –∑–∞–≤–µ—Ä—à—ë–Ω:")
            print(f"  –õ—É—á—à–∏–π AUC (CV): {grid_search.best_score_:.4f}")
            print(f"  –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è {model_name}: {e}")
            results[model_name] = {"error": str(e)}

    return results


def evaluate_tuned_models(
    results: Dict[str, Any], X_test: pd.DataFrame, y_test: pd.Series
) -> Dict[str, Dict[str, Any]]:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ —Å–µ—Ç–∫–µ (—Å CV –Ω–∞ train)
        X_test: –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        y_test: –¢–µ—Å—Ç–æ–≤–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è

    Returns:
        Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
    """
    print(f"\n" + "=" * 60)
    print("–û–¶–ï–ù–ö–ê –ù–ê–°–¢–†–û–ï–ù–ù–´–• –ú–û–î–ï–õ–ï–ô")
    print("=" * 60)

    evaluation_results = {}

    for model_name, model_results in results.items():
        if "error" in model_results:
            print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º {model_name} –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏")
            continue

        print(f"\n–û—Ü–µ–Ω–∫–∞ {model_name}...")

        try:
            best_model = model_results["best_estimator"]

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred = best_model.predict(X_test)
            y_proba = best_model.predict_proba(X_test)[:, 1]

            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics = {
                "accuracy": accuracy_score(y_test, y_pred),
                "precision": precision_score(y_test, y_pred, zero_division=0),
                "recall": recall_score(y_test, y_pred, zero_division=0),
                "f1": f1_score(y_test, y_pred, zero_division=0),
                "roc_auc": roc_auc_score(y_test, y_proba),
            }

            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
            cv_scores = cross_val_score(best_model, X_test, y_test, cv=5, scoring="roc_auc", n_jobs=-1)
            metrics["cv_auc_mean"] = cv_scores.mean()
            metrics["cv_auc_std"] = cv_scores.std()

            evaluation_results[model_name] = {
                "metrics": metrics,
                "predictions": y_pred,
                "probabilities": y_proba,
                "best_params": model_results["best_params"],
                "cv_score": model_results["best_score"],
            }

            print(f"{model_name}:")
            print(f"  Accuracy: {metrics['accuracy']:.4f}")
            print(f"  Precision: {metrics['precision']:.4f}")
            print(f"  Recall: {metrics['recall']:.4f}")
            print(f"  F1-Score: {metrics['f1']:.4f}")
            print(f"  ROC-AUC: {metrics['roc_auc']:.4f}")
            print(f"  CV AUC (–Ω–∞ train): {model_results['best_score']:.4f}")
            print(f"  CV AUC (–Ω–∞ test): {metrics['cv_auc_mean']:.4f} ¬± {metrics['cv_auc_std']:.4f}")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ {model_name}: {e}")
            evaluation_results[model_name] = {"error": str(e)}

    return evaluation_results


def create_hyperparameter_plots(
    results: Dict[str, Any], output_dir: str = "models/artifacts"
) -> None:
    """
    –°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ —Å–µ—Ç–∫–µ
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    for model_name, model_results in results.items():
        if "error" in model_results or "cv_results" not in model_results:
            continue

        try:
            cv_results = model_results["cv_results"]
            param_names = [key for key in cv_results.keys() if key.startswith("param_classifier")]

            if not param_names:
                continue

            fig, axes = plt.subplots((len(param_names) + 1) // 2, 2, figsize=(12, 8))
            if len(param_names) == 1:
                axes = [axes]

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Å–∏
            flat_axes = axes.ravel() if hasattr(axes, 'ravel') else [axes] if len(param_names) == 1 else axes.flatten()

            for i, param_name in enumerate(param_names):
                if i >= len(flat_axes):
                    break
                ax = flat_axes[i]
                param_values = cv_results[param_name]
                mean_scores = cv_results["mean_test_score"]

                # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ç—Ä–æ–∏–º –ª–∏–Ω–∏—é, –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö - –±–∞—Ä
                if all(isinstance(v, (int, float, np.number)) for v in param_values.data if pd.notna(v)):
                    unique_vals = sorted(set(param_values.data))
                    scores = [mean_scores[param_values == v].mean() for v in unique_vals]
                    ax.plot(unique_vals, scores, "o-")
                else:
                    unique_vals = list(set(str(v) for v in param_values.data))
                    scores = [mean_scores[param_values == v].mean() for v in unique_vals]
                    ax.bar(unique_vals, scores, alpha=0.7)

                ax.set_title(f"{param_name.replace('param_classifier__', '').replace('_', ' ').title()}")
                ax.set_ylabel("CV Score")
                ax.grid(True, alpha=0.3)

            plt.suptitle(f"–ê–Ω–∞–ª–∏–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {model_name}", fontsize=16)
            plt.tight_layout()

            plot_path = output_path / f"hyperparameter_analysis_{model_name.lower()}.png"
            plt.savefig(plot_path, dpi=300, bbox_inches="tight")
            plt.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–ø–æ–ª–Ω—è—Ç—å –ø–∞–º—è—Ç—å

            print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –¥–ª—è {model_name}: {e}")


def create_comparison_plot(
    evaluation_results: Dict[str, Dict[str, Any]], output_dir: str = "models/artifacts"
) -> None:
    """
    –°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

    Args:
        evaluation_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")

    valid_results = {k: v for k, v in evaluation_results.items() if "error" not in v and "metrics" in v}
    if not valid_results:
        print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
        return

    metrics = ["accuracy", "precision", "recall", "f1", "roc_auc"]
    model_names = list(valid_results.keys())

    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()

    for i, metric in enumerate(metrics):
        values = [valid_results[m]["metrics"][metric] for m in model_names]
        bars = axes[i].bar(model_names, values, alpha=0.8)
        axes[i].set_title(metric.upper())
        axes[i].set_ylabel("Score")
        axes[i].tick_params(axis="x", rotation=45)
        for bar, val in zip(bars, values):
            axes[i].text(bar.get_x() + bar.get_width()/2, val + 0.01, f"{val:.3f}", ha="center", va="bottom")

    axes[5].remove()
    plt.suptitle("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", fontsize=16)
    plt.tight_layout()

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    plot_path = output_path / "tuned_models_comparison.png"
    plt.savefig(plot_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")


def save_tuned_models(
    results: Dict[str, Any],
    evaluation_results: Dict[str, Dict[str, Any]],
    output_dir: str = "models/trained",
) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ —Å–µ—Ç–∫–µ
        evaluation_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ {output_path}...")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
    for model_name, model_results in results.items():
        if "error" not in model_results and "best_estimator" in model_results:
            model_path = output_path / f"tuned_{model_name.lower()}.pkl"
            joblib.dump(model_results["best_estimator"], model_path)
            print(f"  {model_name} -> {model_path}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if evaluation_results:
        results_data = []
        for model_name, model_results in evaluation_results.items():
            if "error" not in model_results and "metrics" in model_results:
                row = {"model": model_name, **model_results["metrics"], **model_results["best_params"]}
                results_data.append(row)

        if results_data:
            results_df = pd.DataFrame(results_data)
            csv_path = output_path / "tuned_models_results.csv"
            results_df.to_csv(csv_path, index=False)
            print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã -> {csv_path}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model_name = max(
        [name for name in evaluation_results if "error" not in evaluation_results[name]],
        key=lambda x: evaluation_results[x]["metrics"].get("roc_auc", 0),
        default=None
    )
    if best_model_name and "best_estimator" in results.get(best_model_name, {}):
        best_model = results[best_model_name]["best_estimator"]
        best_path = output_path / "best_tuned_model.pkl"
        joblib.dump(best_model, best_path)
        print(f"  –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å ({best_model_name}) -> {best_path}")


def print_final_results(evaluation_results: Dict[str, Dict[str, Any]]) -> None:
    """
    –í—ã–≤–æ–¥–∏—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

    Args:
        evaluation_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
    """
    print("\n" + "=" * 60)
    print("–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ù–ê–°–¢–†–û–ï–ù–ù–´–• –ú–û–î–ï–õ–ï–ô")
    print("=" * 60)

    if not evaluation_results:
        print("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    results_data = []
    for model_name, model_results in evaluation_results.items():
        if "error" not in model_results and "metrics" in model_results:
            results_data.append({"model": model_name, **model_results["metrics"]})

    if not results_data:
        print("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
        return

    results_df = pd.DataFrame(results_data).sort_values("roc_auc", ascending=False)
    print("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:")
    print(results_df.round(4))

    best_row = results_df.iloc[0]
    print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_row['model']} (ROC-AUC: {best_row['roc_auc']:.4f})")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    print("üöÄ –ó–ê–ü–£–°–ö –ü–û–î–ë–û–†–ê –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í –° GRIDSEARCHCV")
    print("=" * 60)

    try:
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        X_train, X_test, y_train, y_test = load_processed_data()

        # 2. –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        preprocessor = create_preprocessor(X_train)

        # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ—Ç–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        param_grids = define_parameter_grids()

        # 4. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        grid_search_results = perform_grid_search(X_train, y_train, preprocessor, param_grids, cv=5)

        # 5. –û—Ü–µ–Ω–∏–≤–∞–µ–º
        evaluation_results = evaluate_tuned_models(grid_search_results, X_test, y_test)

        # 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        create_hyperparameter_plots(grid_search_results)
        create_comparison_plot(evaluation_results)

        # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        save_tuned_models(grid_search_results, evaluation_results)

        # 8. –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print_final_results(evaluation_results)

        print("\n" + "=" * 60)
        print("‚úÖ –ü–û–î–ë–û–† –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û")
        print("=" * 60)

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        raise


if __name__ == "__main__":
    main()
